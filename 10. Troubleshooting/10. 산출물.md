# sub-task : Troubleshooting 산출물

[1. 모니터링](#1-모니터링)<br>
- [1.1. 모니터링 1](#1-1-kube-api-의-로그-모니터링-후-error-오류가-있는-로그-라인-추출extract해서-subtaskcustom-log001-파일에-저장후-출력하세요)<br>
- [1.2. 모니터링 2](#1-2-kubectl-명령을-사용하여-pod중-cpu를-가장-많이-사용하는-순서대로-출력하세요)<br>
- [1.3. 모니터링 3](#1-3-kubectl-명령을-사용하여-node중-메모리를-가장-적게-사용하는-순서대로-출력하세요)<br>
- [1.4. 모니터링 4](#1-4-kubectl-명령을-사용하여-클러스터에-구성된-모든-pv를-capacity별로-sort하여-출력하세요-json-포멧-활용)<br>
- [1.5. 모니터링 5](#1-5-kubectl-명령을-사용하여-클러스터-내-pod의-전체-레이블을-확인-후-배포된-pod중-레이블을-임의로-선택하고-선택한-레이블을-사용하는-pod들-중-cpu-소비율이-가장-높은-pod의-이름을-찾아서-출력하세요)<br>

# 1. 모니터링

## 1-1. kube-api 의 로그 모니터링 후 'error' 오류가 있는 로그 라인 추출(Extract)해서 /subtask/CUSTOM-LOG001 파일에 저장후 출력하세요.

    // 로그 파일 생성
    $ kubectl logs kube-apiserver-qna-cluster-001 -n kube-system | grep 'error' > CUSTOM-LOG001

    // 로그 파일 확인
    $ cat CUSTOM-LOG001 
        Error updating APIService "v1beta1.metrics.k8s.io" with err: failed to download v1beta1.metrics.k8s.io: failed to retrieve openAPI spec, http error: ResponseCode: 503, Body: error trying to reach service: dial tcp 10.233.29.204:443: i/o timeout
        loading OpenAPI spec for "v1beta1.metrics.k8s.io" failed with: failed to download v1beta1.metrics.k8s.io: failed to retrieve openAPI spec, http error: ResponseCode: 503, Body: error trying to reach service: dial tcp 10.233.29.204:443: i/o timeout

## 1-2. kubectl 명령을 사용하여 POD중 CPU를 가장 많이 사용하는 순서대로 출력하세요.

    $ kubectl top pods -A --sort-by=cpu
    NAMESPACE        NAME                                              CPU(cores)   MEMORY(bytes)   
    kube-system      kube-apiserver-qna-cluster-002                    36m          380Mi           
    kube-system      kube-apiserver-qna-cluster-001                    32m          415Mi           
    kube-system      kube-apiserver-qna-cluster-003                    28m          490Mi           
    kube-system      calico-node-5tg49                                 14m          170Mi           
    kube-system      calico-node-nxb5n                                 13m          195Mi           

## 1-3. kubectl 명령을 사용하여 NODE중 메모리를 가장 적게 사용하는 순서대로 출력하세요.

    $ kubectl top node | sort -k4 -h
    NAME              CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   
    qna-cluster-004   33m          2%     1743Mi          24%       
    qna-cluster-001   84m          6%     1808Mi          59%       
    qna-cluster-003   66m          4%     1944Mi          63%       
    qna-cluster-002   72m          5%     1985Mi          65%

## 1-4. kubectl 명령을 사용하여 클러스터에 구성된 모든 PV를 capacity별로 sort하여 출력하세요. (json 포멧 활용)

    $ kubectl get pv -o json | jq '.items | sort_by(.spec.capacity.storage)[] | [.metadata.name, .spec.capacity.storage] | @tsv'
    "pvc-12ae4fa8-1025-43fc-8257-5fad595db2aa\t10Mi"
    "pvc-909c8d13-7406-411b-9c5c-41e58ed47646\t10Mi"
    "pvc-e6d36418-497e-492f-9fde-67328981f16a\t10Mi"
    "pv001\t1Gi"
    "pv001-yang\t1Gi"

## 1-5. kubectl 명령을 사용하여 클러스터 내 POD의 전체 레이블을 확인 후 배포된 POD중 레이블을 임의로 선택하고, 선택한 레이블을 사용하는 Pod들 중 CPU 소비율이 가장 높은 Pod의 이름을 찾아서 출력하세요.

    // 파드 라벨까지 조회
    $ kubectl get pods -A --show-labels
    NAMESPACE        NAME                                              READY   STATUS      RESTARTS   AGE   LABELS
    default          nfs-subdir-external-provisioner-8989f7c84-pds7b   1/1     Running     0          20d   app=nfs-subdir-external-provisioner,pod-template-hash=8989f7c84,release=nfs-subdir-external-provisioner
    ingress-nginx    ingress-nginx-controller-59ccd79866-ftwdb         1/1     Running     0          15h   app.kubernetes.io/component=controller,app.kubernetes.io/instance=ingress-nginx,

    // app=metallb 파드 중에 이름만 조회
    $ kubectl top pod -A --selector=app=metallb --sort-by=cpu --no-headers | head -n 1 | awk '{print $2}'
    speaker-jzkks